# -*- coding: utf-8 -*-
"""maskdetector.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fLp45pnSCRIBeCcBOepuqfU3XxTldRD3
"""

# Импорты
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.preprocessing.image import img_to_array
from tensorflow.keras.preprocessing.image import load_img

from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input

from tensorflow.keras.layers import AveragePooling2D
from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import Flatten
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Input

from tensorflow.keras.models import Model
from tensorflow.keras.models import load_model

from tensorflow.keras.optimizers import Adam

from tensorflow.keras.utils import to_categorical

from sklearn.preprocessing import LabelBinarizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

import imutils.paths
from imutils.video import VideoStream
import matplotlib.pyplot as plt
import numpy as np
import time

import os
import cv2
import argparse
import sys

arg_parser = argparse.ArgumentParser()
arg_parser.add_argument("-f", "--face", type=str, default="face_detector", help="Путь к модели детектора лица")
arg_parser.add_argument("-m", "--model", type=str, default="mask_model", help="Путь к модели детектора маски")
arg_parser.add_argument("-c", "--confidence", type=float, default=0.5, help="Пороговое значение вероятности обнаруженного лица")

args = vars(arg_parser.parse_args())

prototxtPath = '%s/deploy.prototxt' % args['face']
weightsPath = '%s/res10_300x300_ssd_iter_140000.caffemodel' % args['face']

net = cv2.dnn.readNet(prototxtPath, weightsPath)
model = load_model(args["model"])

def predict(frame):
  (h, w) = frame.shape[:2]
  blob = cv2.dnn.blobFromImage(frame, 1.0, (300, 300),
    (104.0, 177.0, 123.0))

  net.setInput(blob)
  detections = net.forward()

  # для всех найденных лиц
  for i in range(0, detections.shape[2]):
    confidence = detections[0, 0, i, 2]

    # Выбираем области, где вероятность, что это лицо - более заданной
    if confidence > 0.3:
      box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])
      (startX, startY, endX, endY) = box.astype("int")
      (startX, startY) = (max(0, startX), max(0, startY))
      (endX, endY) = (min(w - 1, endX), min(h - 1, endY))

      face = frame[startY:endY, startX:endX]
      face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)
      face = cv2.resize(face, (224, 224))
      face = img_to_array(face)
      face = preprocess_input(face)
      face = np.expand_dims(face, axis=0)

      (mask, nomask) = model.predict(face)[0]

      label = "N"
      color = (55, 55, 255)
      if mask > nomask:
        label = "Y"
        color = (55, 255, 55)

      label = "{} {:.2f}%".format(label, max(mask, nomask) * 100)

      cv2.rectangle(frame, (startX, startY), (endX, endY), color, 2)
      cv2.putText(frame, label, (startX + 5, startY + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.3, color, 1)

  return frame

vs = VideoStream(src=0).start()
time.sleep(1.0)

while True:
  # Читаем очередной фрейм
  frame = vs.read()
  frame = imutils.resize(frame, width=400)

  try:
    frame = predict(frame)
  except:
    print("Unexpected error:", sys.exc_info()[0])
  cv2.imshow("Frame", frame)
  key = cv2.waitKey(1) & 0xFF

  # Выходим из цикла при нажатии `q`
  if key == ord("q"):
    break

# do a bit of cleanup
cv2.destroyAllWindows()
vs.stop()